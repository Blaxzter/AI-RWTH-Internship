@article{DESIR20133490,
title = {One class random forests},
journal = {Pattern Recognition},
volume = {46},
number = {12},
pages = {3490-3506},
year = {2013},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2013.05.022},
url = {https://www.sciencedirect.com/science/article/pii/S003132031300246X},
author = {Chesner Désir and Simon Bernard and Caroline Petitjean and Laurent Heutte},
keywords = {One class classification, Supervised learning, Decision trees, Ensemble methods, Random forests, Outlier generation, Outlier detection},
abstract = {One class classification is a binary classification task for which only one class of samples is available for learning. In some preliminary works, we have proposed One Class Random Forests (OCRF), a method based on a random forest algorithm and an original outlier generation procedure that makes use of classifier ensemble randomization principles. In this paper, we propose an extensive study of the behavior of OCRF, that includes experiments on various UCI public datasets and comparison to reference one class namely, Gaussian density models, Parzen estimators, Gaussian mixture models and One Class SVMs—with statistical significance. Our aim is to show that the randomization principles embedded in a random forest algorithm make the outlier generation process more efficient, and allow in particular to break the curse of dimensionality. One Class Random Forests are shown to perform well in comparison to other methods, and in particular to maintain stable performance in higher dimension, while the other algorithms may fail.}
}