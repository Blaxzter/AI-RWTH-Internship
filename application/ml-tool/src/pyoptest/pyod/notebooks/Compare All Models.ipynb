{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Comparing All Implemented Outlier Detection Models\n",
    "\n",
    "**[PyOD](https://github.com/yzhao062/pyod)** is a comprehensive **Python toolkit** to **identify outlying objects** in \n",
    "multivariate data with both unsupervised and supervised approaches.\n",
    "The model covered in this example includes:\n",
    "\n",
    "  1. Linear Models for Outlier Detection:\n",
    "     1. **PCA: Principal Component Analysis** use the sum of\n",
    "       weighted projected distances to the eigenvector hyperplane \n",
    "       as the outlier outlier scores)\n",
    "     2. **MCD: Minimum Covariance Determinant** (use the mahalanobis distances \n",
    "       as the outlier scores)\n",
    "     3. **OCSVM: One-Class Support Vector Machines**\n",
    "     \n",
    "  2. Proximity-Based Outlier Detection Models:\n",
    "     1. **LOF: Local Outlier Factor**\n",
    "     2. **CBLOF: Clustering-Based Local Outlier Factor**\n",
    "     3. **kNN: k Nearest Neighbors** (use the distance to the kth nearest \n",
    "     neighbor as the outlier score)\n",
    "     4. **Median kNN** Outlier Detection (use the median distance to k nearest \n",
    "     neighbors as the outlier score)\n",
    "     5. **HBOS: Histogram-based Outlier Score**\n",
    "     \n",
    "  3. Probabilistic Models for Outlier Detection:\n",
    "     1. **ABOD: Angle-Based Outlier Detection**\n",
    "  \n",
    "  4. Outlier Ensembles and Combination Frameworks\n",
    "     1. **Isolation Forest**\n",
    "     2. **Feature Bagging**\n",
    "     3. **LSCP**\n",
    "     \n",
    "Corresponding file could be found at /examples/compare_all_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1095: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1340: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1476: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "/Users/fredericabraham/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "# Import all models\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.lscp import LSCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the number of inliers and outliers\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0]\n",
    "\n",
    "# Compare given detectors under given settings\n",
    "# Initialize the data\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.zeros(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = 1\n",
    "\n",
    "# initialize a set of detectors for LSCP\n",
    "detector_list = [LOF(n_neighbors=5), LOF(n_neighbors=10), LOF(n_neighbors=15),\n",
    "                 LOF(n_neighbors=20), LOF(n_neighbors=25), LOF(n_neighbors=30),\n",
    "                 LOF(n_neighbors=35), LOF(n_neighbors=40), LOF(n_neighbors=45),\n",
    "                 LOF(n_neighbors=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 150\n",
      "Number of outliers: 50\n",
      "Ground truth shape is (200,). Outlier are 1 and inliers are 0.\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Show the statics of the data\n",
    "print('Number of inliers: %i' % n_inliers)\n",
    "print('Number of outliers: %i' % n_outliers)\n",
    "print('Ground truth shape is {shape}. Outlier are 1 and inliers are 0.\\n'.format(shape=ground_truth.shape))\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "# Define nine outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    'Angle-based Outlier Detector (ABOD)':\n",
    "        ABOD(contamination=outliers_fraction),\n",
    "    'Cluster-based Local Outlier Factor (CBLOF)':\n",
    "        CBLOF(contamination=outliers_fraction,\n",
    "              check_estimator=False, random_state=random_state),\n",
    "    'Feature Bagging':\n",
    "        FeatureBagging(LOF(n_neighbors=35),\n",
    "                       contamination=outliers_fraction,\n",
    "                       random_state=random_state),\n",
    "    'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
    "        contamination=outliers_fraction),\n",
    "    'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                random_state=random_state),\n",
    "    'K Nearest Neighbors (KNN)': KNN(\n",
    "        contamination=outliers_fraction),\n",
    "    'Average KNN': KNN(method='mean',\n",
    "                       contamination=outliers_fraction),\n",
    "    'Local Outlier Factor (LOF)':\n",
    "        LOF(n_neighbors=35, contamination=outliers_fraction),\n",
    "    'Minimum Covariance Determinant (MCD)': MCD(\n",
    "        contamination=outliers_fraction, random_state=random_state),\n",
    "    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
    "    'Principal Component Analysis (PCA)': PCA(\n",
    "        contamination=outliers_fraction, random_state=random_state),\n",
    "    'Locally Selective Combination (LSCP)': LSCP(\n",
    "        detector_list, contamination=outliers_fraction,\n",
    "        random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Angle-based Outlier Detector (ABOD)\n",
      "Model 2 Cluster-based Local Outlier Factor (CBLOF)\n",
      "Model 3 Feature Bagging\n",
      "Model 4 Histogram-base Outlier Detection (HBOS)\n",
      "Model 5 Isolation Forest\n",
      "Model 6 K Nearest Neighbors (KNN)\n",
      "Model 7 Average KNN\n",
      "Model 8 Local Outlier Factor (LOF)\n",
      "Model 9 Minimum Covariance Determinant (MCD)\n",
      "Model 10 One-class SVM (OCSVM)\n",
      "Model 11 Principal Component Analysis (PCA)\n",
      "Model 12 Locally Selective Combination (LSCP)\n"
     ]
    }
   ],
   "source": [
    "# Show all detectors\n",
    "for i, clf in enumerate(classifiers.keys()):\n",
    "    print('Model', i + 1, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/fredericabraham/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/212.5284.44/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_utils.py\", line 64, in attach_to_debugger\n",
      "    debugger.prepare_to_run(enable_tracing_from_start=False)\n",
      "TypeError: prepare_to_run() got an unexpected keyword argument 'enable_tracing_from_start'\n",
      "Failed to connect to target debugger.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fitting Angle-based Outlier Detector (ABOD)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/1v/0j8g8vq122n0v7r6rr_x8pvr0000gn/T/ipykernel_54390/4000068499.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;31m# plot the levels lines and the points\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m         \u001B[0mZ\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecision_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0myy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m         \u001B[0mZ\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mZ\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0msubplot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/pyod/models/abod.py\u001B[0m in \u001B[0;36mdecision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethod\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'fast'\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# fast ABOD\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m             \u001B[0;31m# outliers have higher outlier scores\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 253\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_decision_function_fast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    254\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# default ABOD\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_decision_function_default\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/pyod/models/abod.py\u001B[0m in \u001B[0;36m_decision_function_fast\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    305\u001B[0m             \u001B[0mcurr_pt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m             \u001B[0mX_ind\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mind_arr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 307\u001B[0;31m             \u001B[0mpred_score\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_calculate_wocs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurr_pt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX_train_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_ind\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mpred_score\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/pyod/models/abod.py\u001B[0m in \u001B[0;36m_calculate_wocs\u001B[0;34m(curr_pt, X, X_ind)\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0;31m# add the weighted cosine to the list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[0mwcos_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_wcos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurr_pt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwcos_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mvar\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001B[0m in \u001B[0;36mvar\u001B[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001B[0m\n\u001B[1;32m   3701\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3702\u001B[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001B[0;32m-> 3703\u001B[0;31m                          **kwargs)\n\u001B[0m\u001B[1;32m   3704\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3705\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/numpy/core/_methods.py\u001B[0m in \u001B[0;36m_var\u001B[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001B[0m\n\u001B[1;32m    194\u001B[0m def _var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n\u001B[1;32m    195\u001B[0m          where=True):\n\u001B[0;32m--> 196\u001B[0;31m     \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0masanyarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    197\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m     \u001B[0mrcount\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_count_reduce_items\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdims\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkeepdims\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwhere\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/AI-RWTH-Internship/application/ml-tool/venv/lib/python3.7/site-packages/numpy/core/_asarray.py\u001B[0m in \u001B[0;36masanyarray\u001B[0;34m(a, dtype, order, like)\u001B[0m\n\u001B[1;32m    169\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_asanyarray_with_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlike\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlike\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 171\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    172\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x864 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the models with the generated data and \n",
    "# compare model performances\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "\n",
    "    # Fit the model\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        print(i + 1, 'fitting', clf_name)\n",
    "        # fit the data and tag outliers\n",
    "        clf.fit(X)\n",
    "        scores_pred = clf.decision_function(X) * -1\n",
    "        y_pred = clf.predict(X)\n",
    "        threshold = percentile(scores_pred, 100 * outliers_fraction)\n",
    "        n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        subplot = plt.subplot(3, 4, i + 1)\n",
    "        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "                         cmap=plt.cm.Blues_r)\n",
    "        a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
    "                            linewidths=2, colors='red')\n",
    "        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "                         colors='orange')\n",
    "        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white',\n",
    "                            s=20, edgecolor='k')\n",
    "        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black',\n",
    "                            s=20, edgecolor='k')\n",
    "        subplot.axis('tight')\n",
    "        subplot.legend(\n",
    "            [a.collections[0], b, c],\n",
    "            ['learned decision function', 'true inliers', 'true outliers'],\n",
    "            prop=matplotlib.font_manager.FontProperties(size=10),\n",
    "            loc='lower right')\n",
    "        subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        subplot.set_xlim((-7, 7))\n",
    "        subplot.set_ylim((-7, 7))\n",
    "    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
    "    plt.suptitle(\"Outlier detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}